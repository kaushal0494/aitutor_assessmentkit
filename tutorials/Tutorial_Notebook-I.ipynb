{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook-I: Tutorial on Automated Evaluation with AITutor-AssessmentKit  \n",
    "\n",
    "Welcome to this tutorial on evaluating large language model (LLM)-based AI tutors using automated evaluation metrics provided by [AITutor-AssessmentKit]() on [MRBench]() data. This guide demonstrates a systematic approach to assessing the pedagogical effectiveness of AI tutors.  \n",
    "\n",
    "## Key Features  \n",
    "\n",
    "- **Evaluation Across 8 Pedagogical Dimensions**:  \n",
    "  Based on the foundational principles of learning proposed by Maurya et al. (2024), this framework evaluates tutor performance on the following dimensions:  \n",
    "  1. *Mistake Identification*  \n",
    "  2. *Mistake Location*  \n",
    "  3. *Revealing the Answer*  \n",
    "  4. *Providing Guidance*  \n",
    "  5. *Actionability*  \n",
    "  6. *Coherence*  \n",
    "  7. *Tutor Tone*  \n",
    "  8. *Humanlikeness*  \n",
    "\n",
    "- **Assessment of Student Mistake Remediation in the Mathematical Domain**:  \n",
    "  For a given partial conversation between a tutor and a student, where the student's last utterance contains a mistake or demonstrates confusion, the automated evaluation framework provides an in-depth analysis of the tutor's pedagogical performance across the specified dimensions.  \n",
    "\n",
    "- **Evaluation with Public NLP Models and Traditional Machine Learning Models**:  \n",
    "  This AITutor-AssessmentKit leverages publicly available NLP models released by the NLP community as evaluators for various dimensions. For dimensions where no suitable publicly available model exists, traditional machine learning models are employed as ternary classifiers to assign labels to responses.  \n",
    "\n",
    "## Objectives  \n",
    "\n",
    "By the end of this tutorial, you will:  \n",
    "1. Learn how to use evaluation responsse AI tutors on each pedagogical dimension.  \n",
    "2. Explore the available metrics for specific dimensions and analyze tutor responses accordingly.  \n",
    "3. Compare responses from two tutors based on selected metrics and pedagogical dimensions.  \n",
    "4. Generate and save comprehensive evaluation reports across all dimensions.  \n",
    "\n",
    "This hands-on tutorial is designed to equip you with the tools and knowledge necessary to evaluate and enhance the performance of AI tutors in addressing student mistakes effectively.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Overview \n",
    "Example demonstrating the methods, features, and modules associated with AutoEval for the Coherence dimension.  The same structure applies to other evaluation dimensions.\n",
    "| Method Name                          | Functionality                                                        | How to Call                                    |\n",
    "|--------------------------------------|----------------------------------------------------------------------|-----------------------------------------------|\n",
    "| `__init__`                           | Initializes the evaluator and models.                                | --                          |\n",
    "| `_calculate_nli_score`               | Computes NLI-based coherence scores.                                 | `_calculate_nli_score(convs, tutor_model)`    |\n",
    "| `_calculate_bert_score`              | Computes BERTScore-based coherence scores.                           | `_calculate_bert_score(convs, tutor_model)`   |\n",
    "| `compute`                            | Computes coherence scores for all examples using specified metrics.  | `compute(data, metrics, save, file_name)`     |\n",
    "| `_get_metric_method`                 | Retrieves the scoring method for a metric.                           | `_get_metric_method(metric)`                 |\n",
    "| `list_available_metrics`             | Lists all available metrics and their descriptions.                  | `list_available_metrics()`                   |\n",
    "| `get_sample_examples_with_scores`    | Retrieves examples with coherence scores for a given metric.          | `get_sample_examples_with_scores(...)`       |\n",
    "| `compare_tutors_scores`              | Compares scores between two tutor models for a specific metric.       | `compare_tutors_scores(...)`                 |\n",
    "\n",
    "---\n",
    "\n",
    "### **Suggested Order for Testing/Usage**\n",
    "1. Test `list_available_metrics` to understand the available metrics.\n",
    "2. Use `compute` to calculate scores for all metrics.\n",
    "3. Call `_calculate_nli_score` and `_calculate_bert_score` separately to understand individual scoring methods.\n",
    "4. Retrieve specific examples using `get_sample_examples_with_scores`.\n",
    "5. Compare tutor models using `compare_tutors_scores`. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting the environment, configures the system path, and imports necessary modules  \n",
    "and classes for automated evaluation of tutoring systems.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configure the system path to include the parent directory\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "# Import external libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Import AutoEvaluation classes from the assessment toolkit\n",
    "from aitutor_assessmentkit.autoevaluator import (\n",
    "    autoeval, \n",
    "    AutoMistakeIdentificationEvaluator,\n",
    "    AutoMistakeLocationEvaluator,\n",
    "    AutoRevealingOfTheAnswerEvaluator,\n",
    "    AutoProvidingGuidanceEvaluator,\n",
    "    AutoActionabilityEvaluator,\n",
    "    AutoCoherenceEvaluator, \n",
    "    AutoTutorToneEvaluator,\n",
    "    AutoHumanlikenessEvaluator, \n",
    "    AutoEvaluationReport,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Coherence Across Tutor Models Using AutoCoherenceEvaluator\n",
    "\n",
    "In this section, we demonstrate how to evaluate the \"Coherence\" of responses from multiple tutor models using the `AutoCoherenceEvaluator`. The evaluator computes scores based on two coherence metrics: \"Coherence_BERT\" and \"Coherence_NLI,\" which assess the logical consistency and alignment of the tutor's response with the student’s previous responses.\n",
    "\n",
    "The process follows these steps:\n",
    "1. **Evaluator Initialization**: The `AutoCoherenceEvaluator` is initialized with the MRBench dataset (`MRBench_V5.json`), the output directory for saving results, and a list of tutor models to be evaluated (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the evaluation scores for the specified metrics (`Coherence_BERT` and `Coherence_NLI`), and the results are saved in the output directory.\n",
    "3. **Result Display**: The cumulative score of the evaluation is printed, summarizing the coherence performance across all the selected tutor models.\n",
    "\n",
    "The following code executes this evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 169.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 39630.59it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 596205.26it/s]\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Coherence Scores using ['Coherence_BERT', 'Coherence_NLI'] method(a) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coherence_BERT Score for Tutors:   0%|          | 0/9 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Calculating Coherence_BERT Score for Tutors: 100%|██████████| 9/9 [01:04<00:00,  7.18s/it]\n",
      "Calculating Coherence_NLI Score for Tutors:  22%|██▏       | 2/9 [00:04<00:17,  2.48s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating Coherence_NLI Score for Tutors: 100%|██████████| 9/9 [00:32<00:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coherence_BERT': {'Novice': 0.843, 'Expert': 0.843, 'Llama31405B': 0.849, 'GPT4': 0.854, 'Sonnet': 0.844, 'Phi3': 0.826, 'Llama318B': 0.849, 'Mistral': 0.848, 'Gemini': 0.845, 'Overall': 0.845}, 'Coherence_NLI': {'Novice': 0.803, 'Expert': 0.56, 'Llama31405B': 0.853, 'GPT4': 0.777, 'Sonnet': 0.819, 'Phi3': 0.712, 'Llama318B': 0.766, 'Mistral': 0.73, 'Gemini': 0.755, 'Overall': 0.748}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoCoherenceEvaluator with the specified parameters\n",
    "evaluator = AutoCoherenceEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Coherence_BERT', 'Coherence_NLI'])\n",
    "print(cumulative_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Available Metrics\n",
    "This code retrieves and displays the list of available metrics for the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Metric                                        Description\n",
      "0  Coherence_BERT  Uses BERTScore to evaluate coherence between s...\n",
      "1   Coherence_NLI  Uses Natural Language Inference (NLI) to evalu...\n"
     ]
    }
   ],
   "source": [
    "# List the available metrics for the evaluator\n",
    "available_metrics = evaluator.list_available_metrics()\n",
    "print(available_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Sample Examples with Scores\n",
    "This code retrieves a set of sample examples along with their corresponding evaluation scores for a specific tutor model and metric. In this case, the tutor model is set to \"Expert,\" and the metric used is \"Coherence_BERT.\" The number of examples to retrieve is limited to 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Coherence_BERT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Coherence_BERT Score  \n",
       "0                        0.844  \n",
       "1                        0.861  \n",
       "2                        0.822  \n",
       "3                        0.896  \n",
       "4                        0.857  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with scores for the specified tutor model and metric\n",
    "samples = evaluator.get_sample_examples_with_scores(\n",
    "    tutor_model=\"Expert\", \n",
    "    num_examples=5, \n",
    "    metric=\"Coherence_BERT\"\n",
    ")\n",
    "\n",
    "# Display the retrieved samples\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Coherence_NLI Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Coherence_NLI Score  \n",
       "0                       0.893  \n",
       "1                       0.041  \n",
       "2                       0.275  \n",
       "3                       0.047  \n",
       "4                       0.026  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with scores for the specified tutor model and metric\n",
    "samples = evaluator.get_sample_examples_with_scores(\n",
    "    tutor_model=\"Expert\", \n",
    "    num_examples=5, \n",
    "    metric=\"Coherence_NLI\"\n",
    ")\n",
    "\n",
    "# Display the retrieved samples\n",
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Gemini Response</th>\n",
       "      <th>Gemini Coherence_BERT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>it looks like you're on the right track, but r...</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>it looks like you're trying to find the number...</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>\"that's a great guess!  remember, an octagon h...</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>let's look at how many pencils are in the boxe...</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>that's great! now, think about how those 5 gif...</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>290101923</td>\n",
       "      <td>||| tutor: a quadrilateral is a shape with fou...</td>\n",
       "      <td>can you tell me what makes a rectangle special...</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2542-22f36986-95dc-4ccb-b98d-ff52e85d4851</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>you're absolutely right that he needs a total ...</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>292754187</td>\n",
       "      <td>||| student: sorry for the j that i tipe ||| t...</td>\n",
       "      <td>that's a great observation!let's think about i...</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2721-5902970b-2112-4b4c-992d-82014d134668</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>that's great you caught that mistake!remember ...</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>413466564</td>\n",
       "      <td>||| tutor: do you understand that step? ||| tu...</td>\n",
       "      <td>that's a great try! remember, 6 times 6 is 36,...</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "5                                  290101923   \n",
       "6  2542-22f36986-95dc-4ccb-b98d-ff52e85d4851   \n",
       "7                                  292754187   \n",
       "8  2721-5902970b-2112-4b4c-992d-82014d134668   \n",
       "9                                  413466564   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "5  ||| tutor: a quadrilateral is a shape with fou...   \n",
       "6  ||| tutor: hi, could you please provide a step...   \n",
       "7  ||| student: sorry for the j that i tipe ||| t...   \n",
       "8  ||| tutor: hi, could you please provide a step...   \n",
       "9  ||| tutor: do you understand that step? ||| tu...   \n",
       "\n",
       "                                     Gemini Response  \\\n",
       "0  it looks like you're on the right track, but r...   \n",
       "1  it looks like you're trying to find the number...   \n",
       "2  \"that's a great guess!  remember, an octagon h...   \n",
       "3  let's look at how many pencils are in the boxe...   \n",
       "4  that's great! now, think about how those 5 gif...   \n",
       "5  can you tell me what makes a rectangle special...   \n",
       "6  you're absolutely right that he needs a total ...   \n",
       "7  that's a great observation!let's think about i...   \n",
       "8  that's great you caught that mistake!remember ...   \n",
       "9  that's a great try! remember, 6 times 6 is 36,...   \n",
       "\n",
       "   Gemini Coherence_BERT Score  \n",
       "0                        0.849  \n",
       "1                        0.851  \n",
       "2                        0.841  \n",
       "3                        0.876  \n",
       "4                        0.850  \n",
       "5                        0.844  \n",
       "6                        0.847  \n",
       "7                        0.809  \n",
       "8                        0.832  \n",
       "9                        0.849  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with scores for the specified tutor model and metric\n",
    "samples = evaluator.get_sample_examples_with_scores(\n",
    "    tutor_model=\"Gemini\", \n",
    "    num_examples=10, \n",
    "    metric=\"Coherence_BERT\"\n",
    ")\n",
    "\n",
    "# Display the first 10 rows of the retrieved samples\n",
    "samples.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Tutor Scores\n",
    "This code compares the evaluation scores between two tutor models with selected metric. It retrieves n examples for the comparison and displays the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Coherence_BERT Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Coherence_BERT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.844</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.861</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.822</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.896</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.857</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Coherence_BERT Score  \\\n",
       "0                        0.844   \n",
       "1                        0.861   \n",
       "2                        0.822   \n",
       "3                        0.896   \n",
       "4                        0.857   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Coherence_BERT Score  \n",
       "0                      0.859  \n",
       "1                      0.875  \n",
       "2                      0.842  \n",
       "3                      0.861  \n",
       "4                      0.858  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores between two tutor models for the specified metric\n",
    "comparison = evaluator.compare_tutors_scores(\n",
    "    tutor_model1=\"Expert\", \n",
    "    tutor_model2=\"GPT4\", \n",
    "    num_examples=5, \n",
    "    metric=\"Coherence_BERT\"\n",
    ")\n",
    "\n",
    "# Display the comparison results\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Coherence_BERT Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Coherence_BERT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.844</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.861</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.822</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.896</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.857</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Coherence_BERT Score  \\\n",
       "0                        0.844   \n",
       "1                        0.861   \n",
       "2                        0.822   \n",
       "3                        0.896   \n",
       "4                        0.857   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Coherence_BERT Score  \n",
       "0                      0.859  \n",
       "1                      0.875  \n",
       "2                      0.842  \n",
       "3                      0.861  \n",
       "4                      0.858  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores between two tutor models for the specified metric\n",
    "comparison = evaluator.compare_tutors_scores(\n",
    "    tutor_model1=\"Expert\", \n",
    "    tutor_model2=\"GPT4\", \n",
    "    num_examples=5, \n",
    "    metric=\"Coherence_BERT\"\n",
    ")\n",
    "\n",
    "# Display the comparison results\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Mistake Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Mistake Identification Using AutoMistakeIdentificationEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoMistakeIdentificationEvaluator` to assess \"Mistake Identification\" across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Mistake_Identification_Heuristic\" metric, which evaluates the tutor’s ability to identify mistakes in student responses.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoMistakeIdentificationEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for storing results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Mistake_Identification_Heuristic\" metric, saving the results to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, summarizing the evaluation results for all tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 271.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 41531.87it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 616356.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Identification Scores using ['Mistake_Identification_Heuristic'] mtrics(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Identification_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 3185.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mistake_Identification_Heuristic': {'Novice': 0.582, 'Expert': 0.395, 'Llama31405B': 0.925, 'GPT4': 0.89, 'Sonnet': 0.75, 'Phi3': 0.385, 'Llama318B': 0.63, 'Mistral': 0.83, 'Gemini': 0.94, 'Overall': 0.714}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoMistakeIdentificationEvaluator with the specified parameters\n",
    "evaluator = AutoMistakeIdentificationEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Mistake_Identification_Heuristic'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistake_Identification_Heuristic</td>\n",
       "      <td>Compute mistake identification scores using he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  \\\n",
       "0  Mistake_Identification_Heuristic   \n",
       "\n",
       "                                         Description  \n",
       "0  Compute mistake identification scores using he...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Mistake_Identification_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Mistake_Identification_Heuristic Score  \n",
       "0                                            0.0  \n",
       "1                                            1.0  \n",
       "2                                            1.0  \n",
       "3                                            0.0  \n",
       "4                                            0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Mistake_Identification_Heuristic Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Mistake_Identification_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Mistake_Identification_Heuristic Score  \\\n",
       "0                                            0.0   \n",
       "1                                            1.0   \n",
       "2                                            1.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Mistake_Identification_Heuristic Score  \n",
       "0                                          1.0  \n",
       "1                                          1.0  \n",
       "2                                          1.0  \n",
       "3                                          1.0  \n",
       "4                                          0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Mistake Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Mistake Location Using AutoMistakeLocationEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoMistakeLocationEvaluator` to assess \"Mistake Location\" across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Mistake_Location_Heuristic\" metric, which evaluates the tutor's ability to accurately locate and identify the position of mistakes in student responses.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoMistakeLocationEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for storing results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Mistake_Location_Heuristic\" metric, saving the results to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, summarizing the evaluation results for all tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 304.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 44311.49it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 645277.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Location Scores using ['Mistake_Location_Heuristic'] mtrics(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Location_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 4122.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mistake_Location_Heuristic': {'Novice': 0.0, 'Expert': 0.265, 'Llama31405B': 0.84, 'GPT4': 0.74, 'Sonnet': 0.455, 'Phi3': 0.27, 'Llama318B': 0.555, 'Mistral': 0.575, 'Gemini': 0.885, 'Overall': 0.554}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = AutoMistakeLocationEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Mistake_Location_Heuristic'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistake_Location_Heuristic</td>\n",
       "      <td>Compute mistake location scores using heuristics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Method  \\\n",
       "0  Mistake_Location_Heuristic   \n",
       "\n",
       "                                         Description  \n",
       "0  Compute mistake location scores using heuristics.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Mistake_Location_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Mistake_Location_Heuristic Score  \n",
       "0                                      0.0  \n",
       "1                                      1.0  \n",
       "2                                      1.0  \n",
       "3                                      0.0  \n",
       "4                                      0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Mistake_Location_Heuristic Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Mistake_Location_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Mistake_Location_Heuristic Score  \\\n",
       "0                                      0.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Mistake_Location_Heuristic Score  \n",
       "0                                    0.0  \n",
       "1                                    1.0  \n",
       "2                                    1.0  \n",
       "3                                    1.0  \n",
       "4                                    0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Revealing of the Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Revealing of the Answer Using AutoRevealingOfTheAnswerEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoRevealingOfTheAnswerEvaluator` to assess the \"Revealing of the Answer\" across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Revealing_Of_The_Answer_Heuristic\" metric, which measures how effectively the tutor reveals the final answer to the student.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoRevealingOfTheAnswerEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for saving results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Revealing_Of_The_Answer_Heuristic\" metric, and the results are saved to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, providing a summary of the evaluation results for all tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 303.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 43169.04it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 631196.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Revealing of the_Answer Scores using ['Revealing_of_the_Answer_Heuristic'] mtrics(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Revealing_of_the_Answer_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 4293.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Revealing_of_the_Answer_Heuristic': {'Novice': 0.0, 'Expert': 0.265, 'Llama31405B': 0.84, 'GPT4': 0.74, 'Sonnet': 0.455, 'Phi3': 0.27, 'Llama318B': 0.555, 'Mistral': 0.575, 'Gemini': 0.885, 'Overall': 0.554}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoRevealingOfTheAnswerEvaluator with the specified parameters\n",
    "evaluator = AutoRevealingOfTheAnswerEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Revealing_of_the_Answer_Heuristic'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revealing_of_the_Answer_Heuristic</td>\n",
       "      <td>Compute revealing of the answer scores using h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Method  \\\n",
       "0  Revealing_of_the_Answer_Heuristic   \n",
       "\n",
       "                                         Description  \n",
       "0  Compute revealing of the answer scores using h...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Revealing_of_the_Answer_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Revealing_of_the_Answer_Heuristic Score  \n",
       "0                                             0.0  \n",
       "1                                             1.0  \n",
       "2                                             1.0  \n",
       "3                                             0.0  \n",
       "4                                             0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Revealing_of_the_Answer_Heuristic Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Revealing_of_the_Answer_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Revealing_of_the_Answer_Heuristic Score  \\\n",
       "0                                             0.0   \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Revealing_of_the_Answer_Heuristic Score  \n",
       "0                                           0.0  \n",
       "1                                           1.0  \n",
       "2                                           1.0  \n",
       "3                                           1.0  \n",
       "4                                           0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Providing Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Providing Guidance Using AutoProvidingGuidanceEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoProvidingGuidanceEvaluator` to assess how effectively the tutor provides guidance across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Providing_Guidance_Uptake\" metric, which measures the extent to which the tutor provides meaningful and helpful guidance to the student.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoProvidingGuidanceEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for saving results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Providing_Guidance_Uptake\" metric, and the results are saved to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, providing a summary of the evaluation results for all the tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 344.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 44487.74it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 638888.65it/s]\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Providing Scores using ['Providing_Guidance_Uptake'] metric(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Providing_Guidance_Uptake Score for Tutors: 100%|██████████| 9/9 [00:09<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Providing_Guidance_Uptake': {'Novice': 0.589, 'Expert': 0.819, 'Llama31405B': 0.973, 'GPT4': 0.974, 'Sonnet': 0.887, 'Phi3': 0.434, 'Llama318B': 0.945, 'Mistral': 0.967, 'Gemini': 0.931, 'Overall': 0.857}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoProvidingGuidanceEvaluator with the specified parameters\n",
    "evaluator = AutoProvidingGuidanceEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Providing_Guidance_Uptake'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Providing_Guidance_Uptake</td>\n",
       "      <td>Providing guidance score using uptake metric.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Method                                    Description\n",
       "0  Providing_Guidance_Uptake  Providing guidance score using uptake metric."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Providing_Guidance_Uptake Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Providing_Guidance_Uptake Score  \n",
       "0                                   0.998  \n",
       "1                                   0.999  \n",
       "2                                   0.957  \n",
       "3                                   0.998  \n",
       "4                                   0.999  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Providing_Guidance_Uptake Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Providing_Guidance_Uptake Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.998</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.998</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Providing_Guidance_Uptake Score  \\\n",
       "0                                   0.998   \n",
       "1                                   0.999   \n",
       "2                                   0.957   \n",
       "3                                   0.998   \n",
       "4                                   0.999   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Providing_Guidance_Uptake Score  \n",
       "0                                 0.999  \n",
       "1                                 0.999  \n",
       "2                                 0.998  \n",
       "3                                 0.999  \n",
       "4                                 0.999  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Actionability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Actionability Using AutoActionabilityEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoActionabilityEvaluator` to assess the \"Actionability\" of the tutor’s responses across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Actionability_Heuristic\" metric, which measures the clarity and effectiveness of the tutor’s actions or suggestions in terms of their ability to drive the learner towards a meaningful next step.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoActionabilityEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for saving results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Actionability_Heuristic\" metric, and the results are saved to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, providing a summary of the evaluation results for all the tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 292.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 44169.17it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 603063.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Actionability Scores using ['Actionability_Heuristic'] mtrics(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Actionability_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 6097.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Actionability_Heuristic': {'Novice': 0.036, 'Expert': 0.645, 'Llama31405B': 0.505, 'GPT4': 0.085, 'Sonnet': 0.245, 'Phi3': 0.17, 'Llama318B': 0.08, 'Mistral': 0.185, 'Gemini': 0.115, 'Overall': 0.247}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoActionabilityEvaluator with the specified parameters\n",
    "evaluator = AutoActionabilityEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Actionability_Heuristic'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actionability_Heuristic</td>\n",
       "      <td>Compute actionability scores using heuristics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Method                                     Description\n",
       "0  Actionability_Heuristic  Compute actionability scores using heuristics."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Actionability_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Actionability_Heuristic Score  \n",
       "0                                   0.0  \n",
       "1                                   0.0  \n",
       "2                                   0.0  \n",
       "3                                   1.0  \n",
       "4                                   1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Actionability_Heuristic Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Actionability_Heuristic Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Actionability_Heuristic Score  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   1.0   \n",
       "4                                   1.0   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Actionability_Heuristic Score  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 1.0  \n",
       "4                                 1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Tutor Tone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Tutor Tone Using AutoTutorToneEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoTutorToneEvaluator` to assess the \"Tutor Tone\" across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Tutor_Tone_FTRoBERTa\" metric, which measures the nature of the tutor’s response in terms of its tone. The tone is categorized into three primary categories: encouraging, neutral, or offensive.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoTutorToneEvaluator` is initialized with the file containing the dataset (`MRBench_V5.json`), the output directory for saving the results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the specified metric (`Tutor_Tone_FTRoBERTa`), and the results are saved to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, providing a summary of the evaluation results for all the tutor models under the given metric.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 270.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 43164.60it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 604366.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Tutor Tone Scores using ['Tutor_Tone_FTRoBERTa'] metric(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Tutor_Tone_FTRoBERTa Score for Tutors: 100%|██████████| 9/9 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tutor_Tone_FTRoBERTa': {'Novice': 0.768, 'Expert': 0.484, 'Llama31405B': 0.305, 'GPT4': 0.387, 'Sonnet': 0.687, 'Phi3': 0.763, 'Llama318B': 0.479, 'Mistral': 0.356, 'Gemini': 0.568, 'Overall': 0.513}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoTutorToneEvaluator with the specified parameters\n",
    "evaluator = AutoTutorToneEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert', 'Llama31405B', 'GPT4', 'Sonnet', 'Phi3', 'Llama318B', 'Mistral', 'Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores for the Tutor Tone using the FTRoBERTa metric, saving the results\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Tutor_Tone_FTRoBERTa'])\n",
    "\n",
    "# Print the cumulative score of the evaluation\n",
    "print(cumulative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tutor_Tone_FTRoBERTa</td>\n",
       "      <td>Tutor Tone score using a fine-tuned RoBERTa mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method                                        Description\n",
       "0  Tutor_Tone_FTRoBERTa  Tutor Tone score using a fine-tuned RoBERTa mo..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Tutor_Tone_FTRoBERTa Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Tutor_Tone_FTRoBERTa Score  \n",
       "0                              0.725  \n",
       "1                              0.420  \n",
       "2                              0.788  \n",
       "3                              0.453  \n",
       "4                              0.237  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Tutor_Tone_FTRoBERTa Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Tutor_Tone_FTRoBERTa Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.725</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.420</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.788</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.453</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Tutor_Tone_FTRoBERTa Score  \\\n",
       "0                              0.725   \n",
       "1                              0.420   \n",
       "2                              0.788   \n",
       "3                              0.453   \n",
       "4                              0.237   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Tutor_Tone_FTRoBERTa Score  \n",
       "0                            0.059  \n",
       "1                            0.825  \n",
       "2                            0.982  \n",
       "3                            0.177  \n",
       "4                            0.516  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dimension: Humanlikeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Humanlikeness Using AutoHumanlikenessEvaluator\n",
    "\n",
    "This section demonstrates the use of the `AutoHumanlikenessEvaluator` to assess the \"Humanlikeness\" of the tutor’s responses across multiple tutor models, using the MRBench dataset. The evaluator calculates the scores based on the \"Humanness_OGPT2\" and \"Humanness_Heuristic\" metrics, which measure the extent to which the responses resemble human-like characteristics such as naturalness, fluidity, and realism.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoHumanlikenessEvaluator` is initialized with the dataset file (`MRBench_V5.json`), the output directory for saving results, and a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.).\n",
    "2. **Score Computation**: The `compute` method calculates the cumulative and individual scores for the \"Humanness_OGPT2\" and \"Humanness_Heuristic\" metrics, and the results are saved to the specified output directory.\n",
    "3. **Result Display**: The cumulative score is printed, providing a summary of the evaluation results for all the tutor models under the given metrics.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 285.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 200/200 [00:00<00:00, 42792.47it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 200/200 [00:00<00:00, 615903.67it/s]\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at openai-community/roberta-large-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Humanlikeness Scores using ['Humanlikeness_OGPT2', 'Humanlikeness_Heuristic'] mtrics(s) for 200 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Humanlikeness_OGPT2 Score for Tutors: 100%|██████████| 9/9 [00:07<00:00,  1.22it/s]\n",
      "Calculating Humanlikeness_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 2594.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Humanlikeness_OGPT2': {'Novice': 0.542, 'Expert': 0.67, 'Llama31405B': 0.847, 'GPT4': 0.859, 'Sonnet': 0.738, 'Phi3': 0.735, 'Llama318B': 0.759, 'Mistral': 0.804, 'Gemini': 0.776, 'Overall': 0.766}, 'Humanlikeness_Heuristic': {'Novice': 0.973, 'Expert': 0.983, 'Llama31405B': 0.71, 'GPT4': 0.815, 'Sonnet': 0.99, 'Phi3': 0.897, 'Llama318B': 0.797, 'Mistral': 0.973, 'Gemini': 0.995, 'Overall': 0.898}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoHumanlikenessEvaluator with the specified parameters\n",
    "evaluator = AutoHumanlikenessEvaluator(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert','Llama31405B','GPT4','Sonnet','Phi3','Llama318B','Mistral','Gemini'],\n",
    ")\n",
    "\n",
    "# Compute the evaluation scores and print the cumulative score\n",
    "cumulative_score, all_scores, _ = evaluator.compute(save=True, metrics=['Humanlikeness_OGPT2', 'Humanlikeness_Heuristic'])\n",
    "\n",
    "# Print the cumulative score\n",
    "print(cumulative_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Humanlikeness_OGPT2</td>\n",
       "      <td>Compute Humanlikeness using a pretrained Rober...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Humanlikeness_Heuristic</td>\n",
       "      <td>Compute Humanlikeness using keyword-based heur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Method                                        Description\n",
       "0      Humanlikeness_OGPT2  Compute Humanlikeness using a pretrained Rober...\n",
       "1  Humanlikeness_Heuristic  Compute Humanlikeness using keyword-based heur..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available evaluation metrics and descriptions\n",
    "evaluator.list_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Humanlikeness_OGPT2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Humanlikeness_OGPT2 Score  \n",
       "0                             0.795  \n",
       "1                             0.799  \n",
       "2                             0.897  \n",
       "3                             0.488  \n",
       "4                             0.952  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve sample examples with their corresponding scores for a specified tutor model and evaluation metric\n",
    "evaluator.get_sample_examples_with_scores()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>History</th>\n",
       "      <th>Expert Response</th>\n",
       "      <th>Expert Humanlikeness_OGPT2 Score</th>\n",
       "      <th>GPT4 Response</th>\n",
       "      <th>GPT4 Humanlikeness_OGPT2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930-b01cb51d-748d-460c-841a-08e4d5cd5cc7</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>but after his jog he still had 2000 steps left</td>\n",
       "      <td>0.795</td>\n",
       "      <td>i see where your confusion is. you subtracted ...</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3711-05b6ce71-9710-4b83-8ad2-e207d306c73e</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>not quite, remember, jam has three boxes full ...</td>\n",
       "      <td>0.799</td>\n",
       "      <td>actually, to find out how many pencils each bo...</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2895106109</td>\n",
       "      <td>||| tutor: examples: triangles, rectangles and...</td>\n",
       "      <td>great try! an octagon has 8 sides (i remember ...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>good try, but a five-sided polygon is actually...</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232-a53cdc95-d429-4503-95b8-a22ddec0a735</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>how many pencils does jam have?</td>\n",
       "      <td>0.488</td>\n",
       "      <td>you've done a good job so far, but there seems...</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4211-015f58b6-1408-417d-aa60-2a069b1a8806</td>\n",
       "      <td>||| tutor: hi, could you please provide a step...</td>\n",
       "      <td>ok. and if she got 5 thank you cards that had ...</td>\n",
       "      <td>0.952</td>\n",
       "      <td>that's correct! now, if 1/3 of the thank you c...</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Conversation ID  \\\n",
       "0   930-b01cb51d-748d-460c-841a-08e4d5cd5cc7   \n",
       "1  3711-05b6ce71-9710-4b83-8ad2-e207d306c73e   \n",
       "2                                 2895106109   \n",
       "3   232-a53cdc95-d429-4503-95b8-a22ddec0a735   \n",
       "4  4211-015f58b6-1408-417d-aa60-2a069b1a8806   \n",
       "\n",
       "                                             History  \\\n",
       "0  ||| tutor: hi, could you please provide a step...   \n",
       "1  ||| tutor: hi, could you please provide a step...   \n",
       "2  ||| tutor: examples: triangles, rectangles and...   \n",
       "3  ||| tutor: hi, could you please provide a step...   \n",
       "4  ||| tutor: hi, could you please provide a step...   \n",
       "\n",
       "                                     Expert Response  \\\n",
       "0     but after his jog he still had 2000 steps left   \n",
       "1  not quite, remember, jam has three boxes full ...   \n",
       "2  great try! an octagon has 8 sides (i remember ...   \n",
       "3                    how many pencils does jam have?   \n",
       "4  ok. and if she got 5 thank you cards that had ...   \n",
       "\n",
       "   Expert Humanlikeness_OGPT2 Score  \\\n",
       "0                             0.795   \n",
       "1                             0.799   \n",
       "2                             0.897   \n",
       "3                             0.488   \n",
       "4                             0.952   \n",
       "\n",
       "                                       GPT4 Response  \\\n",
       "0  i see where your confusion is. you subtracted ...   \n",
       "1  actually, to find out how many pencils each bo...   \n",
       "2  good try, but a five-sided polygon is actually...   \n",
       "3  you've done a good job so far, but there seems...   \n",
       "4  that's correct! now, if 1/3 of the thank you c...   \n",
       "\n",
       "   GPT4 Humanlikeness_OGPT2 Score  \n",
       "0                           0.759  \n",
       "1                           0.995  \n",
       "2                           0.978  \n",
       "3                           0.998  \n",
       "4                           0.879  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the evaluation scores of two tutor models based on a specified metric\n",
    "evaluator.compare_tutors_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Automated Evaluation Report\n",
    "\n",
    "This section demonstrates the use of the `AutoEvaluationReport` to generate an automated evaluation report for multiple tutor models across various metrics, using the MRBench dataset. The evaluator generates the report based on the entire set of tutor models, summarizing the performance and evaluation metrics.\n",
    "\n",
    "The following steps are executed:\n",
    "1. **Evaluator Initialization**: The `AutoEvaluationReport` is initialized with the dataset file (`MRBench_V5.json`), the output directory for saving the results, a list of tutor models to evaluate (e.g., 'Novice', 'Expert', 'GPT4', etc.), and the number of conversation examples to evaluate (`num_conv_examples`). If `-1` is specified, all available examples are used.\n",
    "2. **Report Generation**: The `get_automated_evaluation_report_with_all_models` method is used to compute and generate the automated evaluation report. The results are saved to the specified output directory.\n",
    "3. **Result Display**: The report is displayed, showing the first 10 rows of the evaluation data.\n",
    "\n",
    "The following code runs the evaluation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 282.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 33447.40it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 229196.94it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 324.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 24485.14it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 242445.32it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 324.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 25343.23it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 248183.67it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 339.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 25221.31it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 242445.32it/s]\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 298.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 33182.78it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 216201.24it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 318.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 34017.06it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 218453.33it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 330.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 34577.94it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 227951.30it/s]\n",
      "/home/kaushal.maurya/miniconda3/envs/pds_py310/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 269.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 34981.68it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 225500.22it/s]\n",
      "Loading data: 100%|██████████| 1/1 [00:00<00:00, 250.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 examples from /home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data: 100%|██████████| 10/10 [00:00<00:00, 34865.37it/s]\n",
      "Sanity Check for Tutor Models: 100%|██████████| 10/10 [00:00<00:00, 223101.28it/s]\n",
      "Some weights of the model checkpoint at openai-community/roberta-large-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Identification Scores using ['Mistake_Identification_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Identification_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 39321.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Location Scores using ['Mistake_Location_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Location_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 55269.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Providing Scores using ['Providing_Guidance_Uptake'] metric(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Providing_Guidance_Uptake Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Revealing of the_Answer Scores using ['Revealing_of_the_Answer_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Revealing_of_the_Answer_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 50466.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Actionability Scores using ['Actionability_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Actionability_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 76569.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Coherence Scores using ['Coherence_BERT', 'Coherence_NLI'] method(a) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coherence_BERT Score for Tutors: 100%|██████████| 9/9 [00:03<00:00,  2.50it/s]\n",
      "Calculating Coherence_NLI Score for Tutors:  56%|█████▌    | 5/9 [00:00<00:00,  6.04it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating Coherence_NLI Score for Tutors: 100%|██████████| 9/9 [00:01<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Tutor Tone Scores using ['Tutor_Tone_FTRoBERTa'] metric(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Tutor_Tone_FTRoBERTa Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 42.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Humanlikeness Scores using ['Humanlikeness_OGPT2', 'Humanlikeness_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Humanlikeness_OGPT2 Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 22.41it/s]\n",
      "Calculating Humanlikeness_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 34379.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mistake_Identification_Heuristic</th>\n",
       "      <th>Mistake_Location_Heuristic</th>\n",
       "      <th>Providing_Guidance_Uptake</th>\n",
       "      <th>Revealing_of_the_Answer_Heuristic</th>\n",
       "      <th>Actionability_Heuristic</th>\n",
       "      <th>Coherence_BERT</th>\n",
       "      <th>Coherence_NLI</th>\n",
       "      <th>Tutor_Tone_FTRoBERTa</th>\n",
       "      <th>Humanlikeness_OGPT2</th>\n",
       "      <th>Humanlikeness_Heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novice</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.562</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expert</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31405B</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT4</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonnet</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.679</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama318B</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.732</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemini</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.782</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mistake_Identification_Heuristic  Mistake_Location_Heuristic  \\\n",
       "Novice                                  0.750                       0.000   \n",
       "Expert                                  0.300                       0.200   \n",
       "Llama31405B                             0.900                       0.800   \n",
       "GPT4                                    0.800                       0.500   \n",
       "Sonnet                                  0.600                       0.500   \n",
       "Phi3                                    0.600                       0.300   \n",
       "Llama318B                               0.500                       0.500   \n",
       "Mistral                                 0.800                       0.600   \n",
       "Gemini                                  0.900                       0.700   \n",
       "Overall                                 0.679                       0.488   \n",
       "\n",
       "             Providing_Guidance_Uptake  Revealing_of_the_Answer_Heuristic  \\\n",
       "Novice                           0.540                              0.000   \n",
       "Expert                           0.883                              0.200   \n",
       "Llama31405B                      0.998                              0.800   \n",
       "GPT4                             0.997                              0.500   \n",
       "Sonnet                           0.903                              0.500   \n",
       "Phi3                             0.740                              0.300   \n",
       "Llama318B                        0.989                              0.500   \n",
       "Mistral                          0.994                              0.600   \n",
       "Gemini                           0.888                              0.700   \n",
       "Overall                          0.906                              0.488   \n",
       "\n",
       "             Actionability_Heuristic  Coherence_BERT  Coherence_NLI  \\\n",
       "Novice                         0.000           0.840          0.749   \n",
       "Expert                         0.500           0.849          0.438   \n",
       "Llama31405B                    0.500           0.853          0.676   \n",
       "GPT4                           0.300           0.855          0.575   \n",
       "Sonnet                         0.300           0.851          0.601   \n",
       "Phi3                           0.400           0.825          0.613   \n",
       "Llama318B                      0.200           0.853          0.855   \n",
       "Mistral                        0.400           0.851          0.571   \n",
       "Gemini                         0.200           0.845          0.660   \n",
       "Overall                        0.333           0.847          0.629   \n",
       "\n",
       "             Tutor_Tone_FTRoBERTa  Humanlikeness_OGPT2  \\\n",
       "Novice                      0.694                0.562   \n",
       "Expert                      0.496                0.700   \n",
       "Llama31405B                 0.555                0.711   \n",
       "GPT4                        0.564                0.858   \n",
       "Sonnet                      0.811                0.679   \n",
       "Phi3                        0.674                0.756   \n",
       "Llama318B                   0.586                0.736   \n",
       "Mistral                     0.417                0.732   \n",
       "Gemini                      0.680                0.782   \n",
       "Overall                     0.603                0.736   \n",
       "\n",
       "             Humanlikeness_Heuristic  \n",
       "Novice                         1.000  \n",
       "Expert                         1.000  \n",
       "Llama31405B                    0.750  \n",
       "GPT4                           0.900  \n",
       "Sonnet                         1.000  \n",
       "Phi3                           0.750  \n",
       "Llama318B                      0.900  \n",
       "Mistral                        1.000  \n",
       "Gemini                         1.000  \n",
       "Overall                        0.917  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the AutoEvaluationReport with the specified parameters\n",
    "evaluator = AutoEvaluationReport(\n",
    "    file_names=['/home/kaushal.maurya/AITutor_AssessmentKit/data/MRBench_V5.json'],\n",
    "    output_data_dir='/home/kaushal.maurya/AITutor_AssessmentKit/outputs',\n",
    "    tutor_models=['Novice', 'Expert','Llama31405B','GPT4','Sonnet','Phi3','Llama318B','Mistral','Gemini'],\n",
    "    num_conv_examples=10,\n",
    ")\n",
    "\n",
    "# Generate the automated evaluation report without saving the evaluation data or the report itself\n",
    "report, data = evaluator.get_automated_evaluation_report_with_all_models(save_eval=False, save_report=False)\n",
    "\n",
    "# Display the first 10 rows of the generated report\n",
    "report.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Identification Scores using ['Mistake_Identification_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Identification_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 50874.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mistake Location Scores using ['Mistake_Location_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mistake_Location_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 49800.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Providing Scores using ['Providing_Guidance_Uptake'] metric(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Providing_Guidance_Uptake Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Revealing of the_Answer Scores using ['Revealing_of_the_Answer_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Revealing_of_the_Answer_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 51923.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Actionability Scores using ['Actionability_Heuristic'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Actionability_Heuristic Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 83147.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Coherence Scores using ['Coherence_BERT'] method(a) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Coherence_BERT Score for Tutors: 100%|██████████| 9/9 [00:03<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Tutor Tone Scores using ['Tutor_Tone_FTRoBERTa'] metric(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Tutor_Tone_FTRoBERTa Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Humanlikeness Scores using ['Humanlikeness_OGPT2'] mtrics(s) for 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Humanlikeness_OGPT2 Score for Tutors: 100%|██████████| 9/9 [00:00<00:00, 22.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mistake_Identification_Heuristic</th>\n",
       "      <th>Mistake_Location_Heuristic</th>\n",
       "      <th>Providing_Guidance_Uptake</th>\n",
       "      <th>Revealing_of_the_Answer_Heuristic</th>\n",
       "      <th>Actionability_Heuristic</th>\n",
       "      <th>Coherence_BERT</th>\n",
       "      <th>Tutor_Tone_FTRoBERTa</th>\n",
       "      <th>Humanlikeness_OGPT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novice</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expert</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31405B</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT4</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonnet</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi3</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama318B</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemini</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mistake_Identification_Heuristic  Mistake_Location_Heuristic  \\\n",
       "Novice                                  0.750                       0.000   \n",
       "Expert                                  0.300                       0.200   \n",
       "Llama31405B                             0.900                       0.800   \n",
       "GPT4                                    0.800                       0.500   \n",
       "Sonnet                                  0.600                       0.500   \n",
       "Phi3                                    0.600                       0.300   \n",
       "Llama318B                               0.500                       0.500   \n",
       "Mistral                                 0.800                       0.600   \n",
       "Gemini                                  0.900                       0.700   \n",
       "Overall                                 0.679                       0.488   \n",
       "\n",
       "             Providing_Guidance_Uptake  Revealing_of_the_Answer_Heuristic  \\\n",
       "Novice                           0.540                              0.000   \n",
       "Expert                           0.883                              0.200   \n",
       "Llama31405B                      0.998                              0.800   \n",
       "GPT4                             0.997                              0.500   \n",
       "Sonnet                           0.903                              0.500   \n",
       "Phi3                             0.740                              0.300   \n",
       "Llama318B                        0.989                              0.500   \n",
       "Mistral                          0.994                              0.600   \n",
       "Gemini                           0.888                              0.700   \n",
       "Overall                          0.906                              0.488   \n",
       "\n",
       "             Actionability_Heuristic  Coherence_BERT  Tutor_Tone_FTRoBERTa  \\\n",
       "Novice                         0.000           0.840                 0.694   \n",
       "Expert                         0.500           0.849                 0.496   \n",
       "Llama31405B                    0.500           0.853                 0.555   \n",
       "GPT4                           0.300           0.855                 0.564   \n",
       "Sonnet                         0.300           0.851                 0.811   \n",
       "Phi3                           0.400           0.825                 0.674   \n",
       "Llama318B                      0.200           0.853                 0.586   \n",
       "Mistral                        0.400           0.851                 0.417   \n",
       "Gemini                         0.200           0.845                 0.680   \n",
       "Overall                        0.333           0.847                 0.603   \n",
       "\n",
       "             Humanlikeness_OGPT2  \n",
       "Novice                     0.562  \n",
       "Expert                     0.700  \n",
       "Llama31405B                0.711  \n",
       "GPT4                       0.858  \n",
       "Sonnet                     0.679  \n",
       "Phi3                       0.756  \n",
       "Llama318B                  0.736  \n",
       "Mistral                    0.732  \n",
       "Gemini                     0.782  \n",
       "Overall                    0.736  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the automated evaluation report for the best-performing models and save the results\n",
    "report, data = evaluator.get_automated_evaluation_report_with_best_models(save_eval=False, save_report=False)\n",
    "\n",
    "# Display the first 10 rows of the generated report\n",
    "report.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
